%------------------------------------------------

\begin{fullwidth}
Most data collection is now done using digital data entry
using tools that are specially designed for surveys.
These tools, called \textbf{computer-assisted personal interviewing (CAPI)} software,
provide a wide range of features designed to make
implementing even highly complex surveys easy, scalable, and secure.
However, these are not fully automatic:
you still need to actively design and manage the survey.
Each software has specific practices that you need to follow
to enable features such as Stata-compatibility and data encryption.

You can work in any software you like,
and this guide will present tools and workflows
that are primarily conceptual:
this chapter should provide a motivation for
planning data structure during survey design,
developing surveys that are easy to control for quality and security,
and having proper file storage ready for sensitive PII data.
\end{fullwidth}

%------------------------------------------------

\section{Designing CAPI questionnaires}

CAPI surveys\sidenote{\url{https://dimewiki.worldbank.org/wiki/Computer-Assisted_Personal_Interviews_(CAPI)}}
are primarily created in Excel, Google Sheets,
or software-specific form builders
making them one of the few outputs for which little coding is required.\sidenote{\url{https://dimewiki.worldbank.org/wiki/SurveyCTO_Coding_Practices}}
\marginnote{The \texttt{ietestform} command, part of
\texttt{iefieldkit}, implements form-checking routines
for \textbf{SurveyCTO}, a proprietary implementation of \textbf{Open Data Kit (ODK)}.
You can find a summary
of those practices at \url{https://dimewiki.worldbank.org/wiki/ietestform}}
However, since they make extensive use of logical structure and
relate directly to the data that will be used later,
both the field team and the data team should
collaborate to make sure that the survey suits all needs.\cite{krosnick2018questionnaire}

Generally, this collaboration means building the experimental design
fundamentally into the structure of the survey.
When ID matching and tracking is essential,
the survey should be prepared to verify new data
against \textbf{preloaded data} from master records or from other rounds.
\textbf{Extensive tracking} sections --
in which reasons for \textbf{attrition}, treatment \textbf{contamination}, and
\textbf{loss to follow-up} can be documented --
\index{attrition}\index{contamination}
are essential data components for completing CONSORT records.\cite{begg1996improving}

\textbf{Questionnaire design}\sidenote{\url{https://dimewiki.worldbank.org/wiki/Questionnaire_Design}}
\index{questionnaire design}
is the first task where the data team
and the field team must collaborate on data structure.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Preparing_for_Field_Data_Collection}}
The field-oriented staff and the PIs will likely prefer
to capture a large amount of detailed \textit{information}
in the field, some of which will serve very poorly as \textit{data}.\sidenote{\url{
https://iriss.stanford.edu/sites/g/files/sbiybj6196/f/questionnaire\_design\_1.pdf}}
In particular, \textbf{open-ended responses} and questions which will have
many null or missing responses by design will not be very useful
in statistical analyses unless pre-planned.
You must work with the field team to determine the appropriate amount
of abstraction inherent in linking concepts to responses.\sidenote{\url{
https://www.povertyactionlab.org/sites/default/files/documents/Instrument\%20Design\_Diva\_final.pdf}}
It is always possible to ask for specific responses to questions,
but it is far more useful to ask for things like Likert responses.

Coded responses are always more useful than open-ended responses,
because they reduce the time necessary for post-processing by
expensive specialized staff.
For example, if collecting data on medication use or supplies,
you could collect: the brand name of the product;
the generic name of the product;
the coded compound of the product;
or the broad category to which each product belongs (antibiotic, etc.).
All four may be useful for different reasons,
but the latter two are likely to be the most useful for the analyst.
The coded compound requires providing a translation dictionary
to field staff, but enables automated rapid recoding for analysis
with no loss of information.
The generic class requires agreement on the broad categories of interest,
but allows for much more comprehensible top-line statistics and data quality checks.

Broadly, the questionnaire should be designed as follows.
The workflow will feel much like writing an essay:
begin from broad concepts and slowly flesh out the specifics.
\marginnote{Modules should not be numbered --
they should use a short prefix so they can be easily reordered.
There is not yet a full consensus over how individual questions should be identified:
formats like \texttt{hq\_1} are hard to remember and unpleasant to reorder,
but formats like \texttt{hq\_asked\_about\_loans} quickly become cumbersome.}
The \textbf{theory of change}, \textbf{experimental design},
and any \textbf{pre-analysis plans} should be discussed
and the structure of required data for those conceptualized first.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Literature_Review_for_Questionnaire}}
Next, the conceptual outcomes of interest, as well as the main covariates, classifications,
and other variables needed for the experimental design should be listed out.
The questionnaire \textit{modules} should be outlined based on this list.
Each module should then be expanded into specific indicators to observe in the field.
Finally, the questionnaire can be \textbf{piloted}\sidenote{\url{https://dimewiki.worldbank.org/wiki/Survey_Pilot}}
in a non-experimental sample.
Revisions are made, and the survey is then translated into the appropriate language and programmed electronically.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Questionnaire_Programming}}

%------------------------------------------------

\section{Collecting data securely}

Any established data collection platform will always \textbf{encrypt}\sidenote{\url{https://dimewiki.worldbank.org/wiki/Encryption}}
all data submitted from the field automatically while in transit
(ie, upload or download), so if you use servers hosted by SurveyCTO
this is nothing you need to worry about.
Your data will be encrypted from the time it leaves the device
(in tablet-assisted data collation) or your browser (in web data collection)
until it reaches the server.

\marginnote{Encryption at rest is the only way to ensure
that PII data remains private when it is stored
on someone else’s server on the open internet.
The World Bank’s and many of our donors’ security requirements
for data storage can only be fulfilled by this method.
We recommend keeping your data encrypted whenever PII data is collected --
therefore, we recommend it for all field data collection.}

Encryption in cloud storage, by contrast, is not enabled by default.
This is because the service will not encrypt user data unless you confirm
you know how to operate the encryption system and assume its risks.
Encryption at rest is different from password-protection:
encryption at rest makes the underlying data itself unreadable,
even if accessed, except to users who have a specific private \textbf{keyfile}.
Encryption at rest requires active participation from you, the user,
and you should be fully aware that if your private key is lost,
there is absolutely no way to recover your data.

To enable data encryption in SurveyCTO, for example,
simply select the encryption option
when you create a new form on a SurveyCTO server.
\marginnote{Other data collection services should work similarly,
but the exact implementation of encryption at rest
will vary slightly from service to service.}
At that time, the service will allow you to download -- once --
the keyfile pair needed to decrypt the data.
You must download and store this in a secure location.
Again, we recommend \textbf{LastPass}, a software whose free option
allows you to store passwords as well as small keyfiles like this.
You should make sure the LastPass \textbf{secure note} in which you store the keyfile
is descriptively named to match the survey to which it corresponds.
The Sync data download applications will ask you for the location of this keyfile
when you download and set up data for use.
All you need to do is copy that keyfile to your desktop,
point Sync to it, and the rest is automatic.
Delete the keyfile from your desktop, but not from LastPass,
when you are done accessing the encrypted data.

Finally, you should ensure that all teams take basic precautions
to ensure the security of data, as most problems are due to human error.
Most importantly, all computers, tablets, and accounts used
\textit{must} have a logon password associated with them.
This policy should also be applied to physical data storage
such as flash drives and hard drives;
similarly, files sent to the field containing PII data
such as the sampling list should at least be password-protected.\sidenote{
This can be done using a zip-file creator.
LastPass can also be used to share passwords securely,
and you cannot share passwords across email.}
This step significantly mitigates the risk in case there is
a security breach such as loss, theft, hacking, or a virus,
and adds very little hassle to utilization.


%------------------------------------------------

\section{Overseeing fieldwork and quality assurance}

While the team is in the field, you will be responsible
for making sure that the survey is progressing correctly,\sidenote{\url{https://dimewiki.worldbank.org/wiki/Data_Quality_Assurance_Plan}}
that the collected data matches the survey sample,
and that errors and duplicate observations are resolved
quickly so that the field team can make corrections.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Duplicates_and_Survey_Logs}}
Modern survey software makes it relatively easy
to control for issues in individual surveys,
using a combination of in-built features
such as hard constraints on answer ranges
and soft confirmations or validation questions.

These features allow you to spend more time
looking for issues that the software cannot check auotmatically.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Monitoring_Data_Quality}}
Namely, these will be outliers from the overall distribution
or a group of surveys rather than errors in any one response field
(those can often be flagged by the questionnaire software);
enumerators who are taking too long to complete their work,
``difficult'' groups of respondents who are systematically incomplete;
systematic response errors and outliers.
These are typically done in two main forms:
high-frequency checks (HFCs) and back-checks.

High-frequency checks are carried out on the data side.\sidenote{\url{https://github.com/PovertyAction/high-frequency-checks/wiki}}
First, observations must be validated against the sample list:
this is as straightforward as conducting a \texttt{merge}
of the survey data and checking for mismatches.
Next, observations need to be checked for duplicate entries:
\texttt{ieduplicates}\sidenote{\url{https://dimewiki.worldbank.org/wiki/ieduplicates}}
provides a workflow for collaborating on the resolution of
duplicate entries between you and the field team
Finally, data quality checks
should be run on the data every time it is downloaded
to flag irregularities in observations, sample groups, or enumerators.

Unfortunately, it is very hard to specify in general
what kinds of quality checks should be utilized,
since the content of surveys varies so widely.
Fortunately, you will know your survey very well
by the time it is programmed, and should have a good sense
of the types of things that would raise concerns
that you were unable to program directly into the survey.
Thankfully it is also easy to prepare high-frequency checking code in advance.
Once you have built and piloted the survey form,
you will have some bits of mock data to play with.
Using this data, you should prepare code that outputs
a list of flags from any given dataset.
This HFC code is then ready to run every time you download the data,
and should allow you to rapidly identify issues
that are occurring in fieldwork.

Back-checks\sidenote{\url{https://dimewiki.worldbank.org/wiki/Back_Checks}}
involve more extensive collaboration with the field team,
and are best thought of as direct data audits.
In back-checks, a random subset of the field sample is chosen
and basic information from the full survey is verified
using a small survey re-done with the same respondent.
Back-checks should be done with a substantial portion
of the full sample early in the survey
so that the enumerators and field team
get used to the idea of \textbf{quality assurance}.
Checks should continue throughout fieldwork,
and their content and targeting can be refined if particular
questionnaire items are flagged as error-prone
or specific enumerators or observations appear unusual.

Back-checks cover three main types of questions.
First, they validate basic information that should not change.
This ensures the basic quality control that the right respondent
was interviewed or observed in a given survey,
and flags cases of outright quality failure that need action.
Second, they check the quality of enumeration,
particularly in cases that involve measurement or calculation
on the part of the enumerator.
This can be anything such as correctly calculating plot sizes,
family rosters, or income measurements.
These questions should be carefully validated
to determine whether they are reliable measures
and how much they may vary as a result of difficulty in measurement.
Finally, back-checks confirm that questions are being asked and answered
in a consistent fashion. Some questions, if poorly phrased,
can be hard for the enumerator to express or for all respondents
to understand in an identical fashion.
Changes in responses between original and back-check surveys
of the same respondent
can alert you and the team that changes need to be made
to portions of the survey.

When all data collection is complete,
the survey team should have a final field report
ready for validation against the sample frame and the dataset.
This should contain all the observations that were completed;
it should merge perfectly with the received dataset;
and it should report reasons for any observations not collected.
Reporting of \textbf{missingness} and \textbf{attrition} is critical
to the interpretation of any survey dataset,
so it is important to structure this reporting
such that broad rationales can be grouped into categories
but also that the field team can provide detailed, open-ended responses
for any observations they were unable to complete.
This reporting should be validated and saved
alongside the final raw data, and treated the same way.


%------------------------------------------------

\section{Receiving primary data}

In this section, you finally get your hands on some data!
\marginnote{The \texttt{iefolder} command from \texttt{ietoolkit}
will be your best friend here. This command will set up
the folder structure for all data processing tasks
across all data collection rounds.
\url{https://dimewiki.worldbank.org/iefolder}}
What do we do with it? Data handling is one of the biggest
``black boxes'' in primary research -- it always gets done,
but teams have wildly different approaches for actually doing it.
This section breaks the process into key conceptual steps
and provides at least one practical solution for each.
Initial receipt of data will proceed as follows:
the data will be downloaded, and a ``gold master'' copy
of the raw data should be permanently stored in a secure location.
Then, a ``master'' copy of the data is placed into an encrypted location
that will remain accessible on disk and backed up.
This handling satisfies the rule of three:
there are two on-site copies of the data and one off-site copy,
so the data can never be lost in case of hardware failure.

For this step, the remote location can be a variety of forms:
the cheapest is a long-term cloud storage service
such as Amazon Web Services or Microsoft Azure.
Equally sufficient is a physical hard drive
stored somewhere other than the primary work location.
Enterprise cloud solutions like Microsoft OneDrive
can also work, although because you do not control them
we typically do not recommend this for the gold master copy.
If the service satisfies your security needs,
the raw data can be stored unencrypted here.
If you remain lucky, you will never have to access this copy --
you just want to know it is out there, safe, if you need it.

The copy of the raw data you are going to use
should be handled with care.
Since you will probably need to share it among the team,
it should be placed in an encrypted storage location.
The combination of Dropbox and VeraCrypt
can satisfy this requirement for some teams,
since this will never make the data visible to someone
who gets access to the Dropbox,
without the key to the file that is generated on encryption.
\marginnote{LastPass or equivalent should be used to store and share keys.
Note also that this data copy can never be considered the gold master,
because other users or the service can accidentally delete it.}
\textit{The file must never be placed in Dropbox unencrypted, however.}
The way VeraCrypt works is that it creates a virtual copy
of the unencrypted file outside of Dropbox, and lets you access that copy.
Since you should never edit the raw data, this will not be very cumbersome,
but the unencryption and usage of the raw data is a manual process.
With the raw data securely stored and backed up,
you are ready to move to de-identification, data cleaning, and analysis.
